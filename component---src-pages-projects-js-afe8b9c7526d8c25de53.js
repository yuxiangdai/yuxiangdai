(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{"16l3":function(e,a,t){"use strict";t.r(a),t.d(a,"query",(function(){return h}));var n=t("q1tI"),o=t.n(n),i=t("vOnD"),l=t("Bl7J"),r=t("h2vv"),c=t.n(r),s=(t("bW66"),t("qtV5"),t("Wbzz")),m=(Object(i.a)(s.Link).withConfig({displayName:"StyledLink",componentId:"sc-5v4zvs-0"})(["color:white;&:hover{color:grey;}"]),t("9eSz")),d=t.n(m),u=i.a.div.withConfig({displayName:"projects__ImageContainer",componentId:"aqu1ae-0"})(["display:block;margin-left:auto;margin-right:auto;margin-bottom:10px;"]),p=i.a.div.withConfig({displayName:"projects__Container",componentId:"aqu1ae-1"})(["margin:0 auto;max-width:960px;padding:0px 1.0875rem 1.45rem;padding-top:0;"]),h="3116885817";a.default=function(e){var a=e.data;return o.a.createElement(l.a,null,o.a.createElement("h1",{className:c.a.headerText},"projects"),o.a.createElement(p,{className:c.a.container},o.a.createElement("div",{className:c.a.row},o.a.createElement("div",{className:c.a.projectItem},o.a.createElement("h2",null,"yuxiangdai.com"),o.a.createElement(u,null,o.a.createElement(d.a,{className:c.a.image,fluid:a.image1.childImageSharp.fluid})),o.a.createElement("p",null,"I made this website as an experiment in using the React framework GatsbyJS and GraphQL. I first created a template for the website in Sketch, replicated the features I wanted in Javascript, and finally setup deployments using Github Pages and TravisCI. The photo above shows one of the original Sketch designs I based this site off of in the initial first design.")),o.a.createElement("div",{className:c.a.projectItem},o.a.createElement("h2",null,"Ballance"),o.a.createElement(u,null,o.a.createElement(d.a,{className:c.a.image,fluid:a.image2.childImageSharp.fluid})),o.a.createElement("p",null,"Ballance is a robotics project which uses feedback control and computer vision to balance a ping pong ball on a limited flat surface. I used OpenCV to create a HSV filter to track the ball position based on its color. The position data is sent to an Arduino which sends control signals to the servo motors.")),o.a.createElement("div",{className:c.a.projectItem},o.a.createElement("h2",null,"TellORB"),o.a.createElement(u,null,o.a.createElement(d.a,{className:c.a.image,fluid:a.tellorb.childImageSharp.fluid})),o.a.createElement("p",null,"TellORB was my final year thesis project. The idea was to use a DJI Tello drone to map an unknown indoor environment and allow for navigation commands to be sent on a 2D GUI interface using vSLAM (visual Simultaneous Localization and Mapping) in the form of ORB-SLAM2 and local path planning algorithms. An external Dell XPS13 computer was used for egomotion estimation and a real-time interface to the drone using ROS (Robotics Operating System), UDP, and H264 video decoding.")),o.a.createElement("div",{className:c.a.projectItem},o.a.createElement("h2",null,"Uncanny"),o.a.createElement(u,null,o.a.createElement(d.a,{className:c.a.image,fluid:a.uncanny.childImageSharp.fluid})),o.a.createElement("p",null,"Uncanny was a soup and pop can sorting robot built upon the PIC18F4620 microcontroller. Soup cans were separated from pop cans based on their size. Soup cans were then sorted based on whether or not they still contained a label using conductive V-shaped detectors, which align the can and rotate to drop them into the corresponding bins. Pop cans were sorted based on whether or not they had pop tabs using a push-pull circular conductive detector")),o.a.createElement("div",{className:c.a.projectItem},o.a.createElement("h2",null,"TurtleBot Projects"),o.a.createElement(u,null,o.a.createElement(d.a,{className:c.a.image,fluid:a.turtlebot3.childImageSharp.fluid})),o.a.createElement("p",null,"Various projects were run on the TurtleBot 2 & 3 platforms. These include navigation of unknown environments using laser sensors, mapping of point cloud data using particle filters, global A* path planning, local obstacle avoidance and image detection & feature matching using a Microsoft Kinect sensor.")),o.a.createElement("div",{className:c.a.projectItem},o.a.createElement("h2",null,"KUKA Robotic Arm"),o.a.createElement(u,null,o.a.createElement(d.a,{className:c.a.image,fluid:a.kuka.childImageSharp.fluid})),o.a.createElement("p",null,"Simulations for a 6-axis robotic arm were run on the Robotics Toolbox for MATLAB. Solving the inverse kinematics in the simulation allowed for fine motor control of a real KUKA robotics arm. On the right, the arm is shown drawing various shapes and trajectories with a pencil.")))))}},bW66:function(e,a,t){e.exports=t.p+"static/site-2f98ff7994ad7e626f00925934afcb7e.png"},h2vv:function(e,a,t){e.exports={headerImage:"projects-module--headerImage--vAHqo",image:"projects-module--image--2COyW",container:"projects-module--container--8xGec",row:"projects-module--row--e_nhQ",projectItem:"projects-module--projectItem--2N0uV"}},qtV5:function(e,a,t){e.exports=t.p+"static/ballance-5b00fba0936360fc1854cab032dde3e0.png"}}]);
//# sourceMappingURL=component---src-pages-projects-js-afe8b9c7526d8c25de53.js.map